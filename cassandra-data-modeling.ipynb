{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/src/app\n",
      "['/usr/src/app/event_data/2018-11-01-events.csv', '/usr/src/app/event_data/2018-11-02-events.csv', '/usr/src/app/event_data/2018-11-03-events.csv', '/usr/src/app/event_data/2018-11-04-events.csv', '/usr/src/app/event_data/2018-11-05-events.csv', '/usr/src/app/event_data/2018-11-06-events.csv', '/usr/src/app/event_data/2018-11-07-events.csv', '/usr/src/app/event_data/2018-11-08-events.csv', '/usr/src/app/event_data/2018-11-09-events.csv', '/usr/src/app/event_data/2018-11-10-events.csv']\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "#print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_data_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1595\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_data_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_data_new.csv</font>, located within the Workspace directory.  The event_data_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_data_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "# use `cassandra_db` docker container name as hostname\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['cassandra_db'])\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f064fb6bc10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute('''\n",
    "    CREATE KEYSPACE IF NOT EXISTS cassandra_data_modeling\n",
    "    WITH REPLICATION = {\n",
    "        'class': 'SimpleStrategy',\n",
    "        'replication_factor': 1\n",
    "    }\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.set_keyspace('cassandra_data_modeling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create queries to ask the following three questions of the data\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "For the first query, there should be columns named `artist`, `song`, `length`, `sessionId`, `itemInSession`\n",
    "without duplicate key consideration.\n",
    "\n",
    "Before making `sessionId` and `itemInSession` as composite primary key, let's analyze its uniqueness.\n",
    "\n",
    "Assumption: the composite primary key has one-to-one relation.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column data class preparation & validate method\n",
    "\n",
    "@dataclass\n",
    "class Column:\n",
    "    \"\"\"\n",
    "    A data class to hold column metadata\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    name: str\n",
    "        column name\n",
    "    is_primary_key: bool\n",
    "        flag indicating that this column is a primary key\n",
    "    \"\"\"\n",
    "    \n",
    "    name: str\n",
    "    is_primary_key: bool\n",
    "\n",
    "def validate_column_uniqueness(__df: pd.core.frame.DataFrame, __columns: List[Column]) -> None:\n",
    "    \"\"\"\n",
    "    Validate whether columns are unique according to data frame.\n",
    "    If the uniqueness is not satisfied, AssertionError instance will be raised.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    __df: pd.core.frame.DataFrame\n",
    "        data frame containing data to be validated\n",
    "    __columns: List[Column]\n",
    "        selected columns from what we have in `__df` parameter\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    column_names = [column.name for column in __columns]\n",
    "    primary_column_names = [column.name for column in __columns if column.is_primary_key]\n",
    "    \n",
    "    duplication_analysis_df = __df.groupby(\n",
    "        column_names\n",
    "    ).size(\n",
    "    ).reset_index(\n",
    "        name='counts'\n",
    "    )[column_names].groupby(\n",
    "        primary_column_names\n",
    "    ).size(\n",
    "    ).reset_index(\n",
    "        name='counts'\n",
    "    ).sort_values(\n",
    "        by='counts',\n",
    "        ascending=False\n",
    "    )\n",
    "    \n",
    "    first_row = duplication_analysis_df.iloc[0]\n",
    "    highest_counts = first_row['counts']\n",
    "    \n",
    "    assert highest_counts == 1, f'There are {highest_counts} duplications when columns = {column_names} with primary key of {primary_column_names}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('event_data_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_query_columns = [\n",
    "    Column(column_name, is_primary_key)\n",
    "    for (column_name, is_primary_key)\n",
    "    in [\n",
    "        ('sessionId'    , True),\n",
    "        ('itemInSession', True),\n",
    "        ('artist'       , False),\n",
    "        ('song'         , False),\n",
    "        ('length'       , False)\n",
    "    ]\n",
    "]\n",
    "\n",
    "validate_column_uniqueness(df, first_query_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f064c9594f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS musics_q1 (\n",
    "        session_id      INT,\n",
    "        item_in_session INT,\n",
    "        artist          TEXT,\n",
    "        song            TEXT,\n",
    "        length          DECIMAL,\n",
    "        PRIMARY KEY (session_id, item_in_session)\n",
    "    )\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file = 'event_data_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = '''\n",
    "            INSERT INTO musics_q1 (\n",
    "                session_id,\n",
    "                item_in_session,\n",
    "                artist,\n",
    "                song,\n",
    "                length\n",
    "            )\n",
    "            VALUES (%s, %s, %s, %s, %s)\n",
    "        '''\n",
    "        \n",
    "        session_id = int(line[8])\n",
    "        item_in_session = int(line[3])\n",
    "        artist = line[0]\n",
    "        song = line[9]\n",
    "        length = float(line[5])\n",
    "\n",
    "        session.execute(\n",
    "            query,\n",
    "            (\n",
    "                session_id,\n",
    "                item_in_session,\n",
    "                artist,\n",
    "                song,\n",
    "                length\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithless Music Matters (Mark Knight Dub) 495.3073\n"
     ]
    }
   ],
   "source": [
    "# Narrative 1st query description: Give me the artist, song title and song's length\n",
    "# in the music app history that was heard during sessionId = 338, and itemInSession = 4\n",
    "rows = session.execute('''\n",
    "    SELECT artist, song, length\n",
    "    FROM musics_q1\n",
    "    WHERE session_id = 338\n",
    "    AND item_in_session = 4\n",
    "''')\n",
    "for row in rows:\n",
    "    print(row.artist, row.song, row.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>Faithless</td>\n",
       "      <td>Music Matters (Mark Knight Dub)</td>\n",
       "      <td>495.3073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist                             song    length\n",
       "964  Faithless  Music Matters (Mark Knight Dub)  495.3073"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This data frame should match with CQL query result above.\n",
    "df[\n",
    "    (df['sessionId'] == 338) & (df['itemInSession'] == 4)\n",
    "][['artist', 'song', 'length']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COPY AND REPEAT THE ABOVE THREE CELLS FOR EACH OF THE THREE QUESTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is expected since primary columns ['userId', 'sessionId'] still cause duplication.\n",
      "\n",
      "\n",
      "Here is a full error message: There are 101 duplications when columns = ['userId', 'sessionId', 'artist', 'song', 'firstName', 'lastName', 'itemInSession'] with primary key of ['userId', 'sessionId']\n"
     ]
    }
   ],
   "source": [
    "second_query_columns = [\n",
    "    Column(column_name, is_primary_key)\n",
    "    for (column_name, is_primary_key)\n",
    "    in [\n",
    "        ('userId'       , True),\n",
    "        ('sessionId'    , True),\n",
    "        ('artist'       , False),\n",
    "        ('song'         , False),\n",
    "        ('firstName'    , False),\n",
    "        ('lastName'     , False),\n",
    "        ('itemInSession', False)\n",
    "    ]\n",
    "]\n",
    "\n",
    "try:\n",
    "    validate_column_uniqueness(df, second_query_columns)\n",
    "except AssertionError as e:\n",
    "    primary_column_names = [column.name for column in second_query_columns if column.is_primary_key]\n",
    "    print(f'This is expected since primary columns {primary_column_names} still cause duplication.')\n",
    "    print('\\n')\n",
    "    print(f'Here is a full error message: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we will sort `song` by `itemInSession`,\n",
    "# let's check if additional primary key `itemInSession` satisfied the second table uniqueness\n",
    "\n",
    "second_query_columns = [\n",
    "    Column(column_name, is_primary_key)\n",
    "    for (column_name, is_primary_key)\n",
    "    in [\n",
    "        ('userId'       , True),\n",
    "        ('sessionId'    , True),\n",
    "        ('itemInSession', True),\n",
    "        ('artist'       , False),\n",
    "        ('song'         , False),\n",
    "        ('firstName'    , False),\n",
    "        ('lastName'     , False)\n",
    "    ]\n",
    "]\n",
    "\n",
    "validate_column_uniqueness(df, second_query_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f06467c9f10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS musics_q2 (\n",
    "        user_id         INT,\n",
    "        session_id      INT,\n",
    "        item_in_session INT,\n",
    "        artist          TEXT,\n",
    "        song            TEXT,\n",
    "        first_name      TEXT,\n",
    "        last_name       TEXT,\n",
    "        PRIMARY KEY (user_id, session_id, item_in_session)\n",
    "    )\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_data_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        user_id = int(line[10])\n",
    "        session_id = int(line[8])\n",
    "        item_in_session = int(line[3])\n",
    "        artist = line[0]\n",
    "        song = line[9]\n",
    "        first_name = line[1]\n",
    "        last_name = line[4]\n",
    "        \n",
    "        query = '''\n",
    "            INSERT INTO musics_q2 (\n",
    "                user_id,\n",
    "                session_id,\n",
    "                item_in_session,\n",
    "                artist,\n",
    "                song,\n",
    "                first_name,\n",
    "                last_name\n",
    "            )\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "        '''\n",
    "        \n",
    "        session.execute(\n",
    "            query,\n",
    "            (\n",
    "                user_id,\n",
    "                session_id,\n",
    "                item_in_session,\n",
    "                artist,\n",
    "                song,\n",
    "                first_name,\n",
    "                last_name\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down To The Bone Keep On Keepin' On Sylvie Cruz\n",
      "Three Drives Greece 2000 Sylvie Cruz\n",
      "Sebastien Tellier Kilometer Sylvie Cruz\n",
      "Lonnie Gordon Catch You Baby (Steve Pitron & Max Sanna Radio Edit) Sylvie Cruz\n"
     ]
    }
   ],
   "source": [
    "# Narrative 2nd query description: Give me only the following: name of artist,\n",
    "# song (sorted by itemInSession) and user (first and last name)\n",
    "# for userid = 10, sessionid = 182\n",
    "\n",
    "rows = session.execute('''\n",
    "    SELECT artist, song, first_name, last_name\n",
    "    FROM musics_q2\n",
    "    WHERE user_id = 10\n",
    "    AND session_id = 182\n",
    "    ORDER BY item_in_session\n",
    "''')\n",
    "for row in rows:\n",
    "    print(row.artist, row.song, row.first_name, row.last_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Down To The Bone</td>\n",
       "      <td>Keep On Keepin' On</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Three Drives</td>\n",
       "      <td>Greece 2000</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Sebastien Tellier</td>\n",
       "      <td>Kilometer</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Lonnie Gordon</td>\n",
       "      <td>Catch You Baby (Steve Pitron &amp; Max Sanna Radio...</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                artist                                               song  \\\n",
       "151   Down To The Bone                                 Keep On Keepin' On   \n",
       "152       Three Drives                                        Greece 2000   \n",
       "153  Sebastien Tellier                                          Kilometer   \n",
       "154      Lonnie Gordon  Catch You Baby (Steve Pitron & Max Sanna Radio...   \n",
       "\n",
       "    firstName lastName  \n",
       "151    Sylvie     Cruz  \n",
       "152    Sylvie     Cruz  \n",
       "153    Sylvie     Cruz  \n",
       "154    Sylvie     Cruz  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This data frame should match with CQL query result above.\n",
    "df[\n",
    "    (df['userId'] == 10) & (df['sessionId'] == 182)\n",
    "][\n",
    "    ['artist', 'song', 'firstName', 'lastName', 'itemInSession']\n",
    "].sort_values(\n",
    "    by='itemInSession'\n",
    ")[['artist', 'song', 'firstName', 'lastName']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is expected since primary columns ['song'] still cause duplication.\n",
      "\n",
      "\n",
      "Here is a full error message: There are 9 duplications when columns = ['song', 'firstName', 'lastName'] with primary key of ['song']\n"
     ]
    }
   ],
   "source": [
    "third_query_columns = [\n",
    "    Column(column_name, is_primary_key)\n",
    "    for (column_name, is_primary_key)\n",
    "    in [\n",
    "        ('song', True),\n",
    "        ('firstName', False),\n",
    "        ('lastName', False)\n",
    "    ]\n",
    "]\n",
    "\n",
    "try:\n",
    "    validate_column_uniqueness(df, third_query_columns)\n",
    "except AssertionError as e:\n",
    "    primary_column_names = [column.name for column in third_query_columns if column.is_primary_key]\n",
    "    print(f'This is expected since primary columns {primary_column_names} still cause duplication.')\n",
    "    print('\\n')\n",
    "    print(f'Here is a full error message: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_query_columns = [\n",
    "    Column(column_name, is_primary_key)\n",
    "    for (column_name, is_primary_key)\n",
    "    in [\n",
    "        ('song', True),\n",
    "        ('sessionId', True),\n",
    "        ('firstName', False),\n",
    "        ('lastName', False)\n",
    "    ]\n",
    "]\n",
    "\n",
    "validate_column_uniqueness(df, third_query_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7f064c94b4f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS musics_q3 (\n",
    "        song            TEXT,\n",
    "        session_id      INT,\n",
    "        first_name      TEXT,\n",
    "        last_name       TEXT,\n",
    "        PRIMARY KEY (song, session_id)\n",
    "    )\n",
    "''') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_data_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        song = line[9]\n",
    "        session_id = int(line[8])\n",
    "        first_name = line[1]\n",
    "        last_name = line[4]\n",
    "        \n",
    "        query = '''\n",
    "            INSERT INTO musics_q3 (\n",
    "                song,\n",
    "                session_id,\n",
    "                first_name,\n",
    "                last_name\n",
    "            )\n",
    "            VALUES (%s, %s, %s, %s)\n",
    "        '''\n",
    "        \n",
    "        session.execute(\n",
    "            query,\n",
    "            (\n",
    "                song,\n",
    "                session_id,\n",
    "                first_name,\n",
    "                last_name\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sara Johnson\n"
     ]
    }
   ],
   "source": [
    "# Narrative 3rd query description: Give me every user name (first and last)\n",
    "# in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "rows = session.execute('''\n",
    "    SELECT first_name, last_name\n",
    "    FROM musics_q3\n",
    "    WHERE song = 'All Hands Against His Own'\n",
    "''')\n",
    "for row in rows:\n",
    "    print(row.first_name, row.last_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Sara</td>\n",
       "      <td>Johnson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    firstName lastName\n",
       "219      Sara  Johnson"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This data frame should match with CQL query result above.\n",
    "df[df['song'] == 'All Hands Against His Own'][['firstName', 'lastName']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_name in ['musics_q1', 'musics_q2', 'musics_q3']:\n",
    "    session.execute(f'''\n",
    "        DROP TABLE IF EXISTS {table_name}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
